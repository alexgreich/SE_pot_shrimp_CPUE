---
title: "District 7"
author: "Alex Reich"
date: "2024-04-24"
output: html_document
---
Aside:
Argh, I had to upgrade to R 4.4.0 to get lme4 (the matrix package, specifically) to work. But now the r markdown settings are different and I can't default to the home directory being the project. So I will set that here:
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/agreich/OneDrive - State of Alaska/Desktop/Shrimp/Shrimp tickets (pot shrimp)/SE_pot_shrimp_CPUE')
```



Anyway, let's get started. This document will look at management unit District 7 for pot (spot) shrimp standardization. It will load in the (pre-wrangled) data, wrangle further for district 1, and then some EDA (focusing on variables of interest and correlation). The analysis will be by district with an HGAM (hierarchical GAM) with the variables of interest as fixed effects and Analysis Area as a random effect. I will do model selection on a few versions of this HGAM. I will then make graphs of the standardized CPUE (by district and) and whatever else Max wants. THEN, I will run individual models by analysis areas, ideally with an automated function, and compare the graphs of those automated functions to the cpue of the ranef model.This will help me decide if models should be by MANAGEMENT UNIT (larger) or by ANALYSIS AREA (smaller). In hindsight, I should start with District 7, since I have explored the Upper Ernest sound data extensively.Ok, now the RMD is named accordingly 


Load libraries
```{r}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(viridis)
library(RColorBrewer)
library(mgcv)
```


Load the data and select for D7
```{r}
wrangled_shrimp <- read.csv("Data/wrangled shrimp focus years.csv")
D7 <- wrangled_shrimp %>% filter(Management_unit == "District 7") %>%
  mutate(Analysis.Area = factor(Analysis.Area),
         ADFG.Number = factor(ADFG.Number),
         Season.Ref = factor(Season.Ref)
         )#make things factors for the gams

unique(D7$Analysis.Area)

```


District 7 contains analysis areas:
  Bradfield Canal
  Lower Ernest Sound
  Upper Ernest Sound
  Zimovia Strait
  
  
  
## Exploratory Data Analysis for D7
Variables of interest:
Random effect: Analysis.Area
Fixed effects: jdate (smoothed and... cyclical?), vessel # (the count of vessels), ADFG # (individual vessel (fixed or random effect??)), Season aka year, 
--If I do not include jdate, simplifies things?
Response: nominal cpue

Q: should I do something besides a log-transformation?
```{r}

#cpue dist
ggplot(D7) + aes(x=CPUE_nom) + geom_density()
ggplot(D7) + aes(x=log(CPUE_nom+0.001)) + geom_density()
qqnorm(log(D7$CPUE_nom)) #that kind of looks bad. Maybe somehting other than log-trans?
qqnorm(D7$CPUE_nom)

ggplot(D7) + aes(x=CPUE_nom) + geom_density()+facet_wrap(~Analysis.Area)
ggplot(D7) + aes(x=log(CPUE_nom+0.001)) + geom_density()+facet_wrap(~Analysis.Area)

#cpue by year
ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_point() #ther is a big outlier
ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_boxplot(outliers = F)

ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_boxplot(outliers = F) + facet_wrap(~Analysis.Area) #cpue varies... cyclically with time. Is season a fixed effect? I want to estimate it, so probs not. its def not linear.

#catch by year
ggplot(D7) + aes(x=factor(Season.Ref), y=total_weight) + geom_boxplot() #this is total weight per fish ticket.
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot()
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot(outliers=F)

ggplot(D7) + aes(x=factor(Season.Ref), y=total_weight) + geom_boxplot() + facet_wrap(~Analysis.Area) #max pots per fish ticket
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot(outliers=F) + facet_wrap(~Analysis.Area)


#cpue and vessel count
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot()
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot(outliers=F)
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot(outliers=F) + facet_wrap(~Analysis.Area)

#cpue and district


#cpue and jdate



#correlation plot
library(corrplot)
D7_interest_cor <- D7 %>% select(CPUE_nom, jdate, vessel_count_mgmt_u)
cor_prep <- cor(D7_interest_cor)
corrplot(cor_prep)
?pairs


#check model residuals, see if we need ar1 correlation in the model
```



Some wild experimentation below,
delete later and keep what is useful
```{r}
#null model
m0 <- gam(log(CPUE_nom + 0.001) ~ factor(Season.Ref) ,data= D7, method="ML" ) #how to add temporal autocorrealtion to this tho?

m_glob_r <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + s(ADFG.Number, bs="re")+ s(vessel_count_mgmt_u, k=4) + s(jdate, k=4) + s(Analysis.Area, bs="re", k=4), data=D7 , method="ML") 

m_glob_r_2 <- gam(log(CPUE_nom + 0.001) ~ Season.Ref+ ADFG.Number + s(vessel_count_mgmt_u, k=4) + s(jdate, k=4) + s(Analysis.Area, bs="re", k=4), data=D7, method="ML" )

m_glob_nr <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + ADFG.Number+ s(vessel_count_mgmt_u, k=4) + s(jdate, k=4), data=D7, method="ML") 

#do I need random effects in the model, and which random effects?
AIC(m_glob_r, m_glob_r_2, m_glob_nr, m0) #m glob r wins, but not by much


#get rid some variables
summary(m_glob_r)
m_3 <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + s(ADFG.Number, bs="re")+ s(jdate, k=4) + s(Analysis.Area, bs="re", k=4), data=D7, method="ML" ) 

AIC(m_glob_r, m_3) #same, meaning drop vessel count
summary(m_3)

#oh shit tho, let me check temporal autocorrelation, maybe I should check for interactions
?acf
acf(residuals(m_glob_r),main="raw residual ACF") #yeah, some autocorrelation

#so...what do I do?

#try the global model with interaction effects, see if autocorrelation still exists
#https://r.qcbs.ca/workshop08/book-en/gam-with-interaction-terms.html
#m_glob_r_int <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + s(ADFG.Number, bs="re")+ s(vessel_count_mgmt_u, k=4) + s(jdate, k=4) + s(Analysis.Area, bs="re", k=4), data=D7 , method="ML") +
 #s() #interaction effects

#ok ummm, maybe do smaller levels first to chekc for int
mod_int_1 <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + s(ADFG.Number, bs="re")+ s(vessel_count_mgmt_u, k=4) + s(vessel_count_mgmt_u, by=Season.Ref, k=4) + s(Analysis.Area, bs="re", k=4), data=D7 , method="REML") #

summary(mod_int_1)
summary(m_glob_r)


```


But wait do I even, like, need a GAM?
m_glob_r <- gam(log(CPUE_nom + 0.001) ~ Season.Ref + s(ADFG.Number, bs="re")+ s(vessel_count_mgmt_u, k=4) + s(jdate, k=4) + s(Analysis.Area, bs="re", k=4), data=D7 , method="ML") 
```{r}
#remove outleir
max(D7$CPUE_nom)
D7_no_o <- D7 %>% filter(CPUE_nom < 100)

#log cpue vs. ADFG number (ok thats a radom effect)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=ADFG.Number) + geom_boxplot()
###oh maybe this should be a special random effect. I forget
##this: Random factor smooth interactions
#bs="fs" A special smoother class (see smooth.construct.fs.smooth.spec) is available for the case in which a smooth is required at each of a large number of factor levels (for example a smooth for each patient in a study), and each smooth should have the same smoothing parameter. The "fs" smoothers are set up to be efficient when used with gamm, and have penalties on each null sapce component (i.e. they are fully ‘random effects’). from: https://stat.ethz.ch/R-manual/R-patched/RHOME/library/mgcv/html/smooth.terms.html
#or just a regular random effect. can try both ways. why not

#log cpue vs. season ref (is this smoothed in phil's code??)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Season.Ref) + geom_boxplot(outliers=F) #totally autocorrelated

#log cpue vs. Analysis area (also a random effect)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Analysis.Area) + geom_boxplot() #ok they're not... that different
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Analysis.Area) + geom_boxplot(outliers=F)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Analysis.Area) + geom_violin()

ggplot(D7) + aes(y= CPUE_nom, x=Analysis.Area) + geom_boxplot(outliers=F)
ggplot(D7) + aes(y= CPUE_nom, x=Analysis.Area) + geom_violin()

#log cpue vs jdate (is this worth including, because the season might not be so important to look at, migjt give uneven results since fishing season recently shifted)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=jdate) + geom_smooth() #i think maybe jdate isnt necessary because the fishing season is a specific window.

#log cpue vs. vessel count
##vessel count by year and analysis area
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_aa) + geom_point() + geom_smooth()
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_aa) + geom_smooth() + geom_point() #ok that puts thigs in perspective
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_aa) + geom_smooth(method = "lm")# + geom_point()
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_aa) + geom_smooth(method = "lm") + geom_point()
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_aa) + geom_point()

ggplot(D7_no_o) + aes(y= CPUE_nom, x=vessel_count_aa) +geom_point()+ geom_smooth()
ggplot(D7_no_o) + aes(y= CPUE_nom, x=vessel_count_aa, group=vessel_count_aa) +geom_boxplot()+ geom_smooth()
ggplot(D7_no_o) + aes(y= CPUE_nom, x=vessel_count_aa, color=Season.Ref) +geom_point()
ggplot(D7) + aes(y= CPUE_nom, x=vessel_count_aa) + geom_smooth(method = "lm") #ok teh change in cpue is super small. Like, 1 pound. Idbutk if that matters 
ggplot(D7_no_o) + aes(y= CPUE_nom, x=vessel_count_aa) + geom_smooth(method = "lm") + geom_point()

##vessel count by year and mgmt u
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_mgmt_u) + geom_smooth()
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=vessel_count_mgmt_u) + geom_point()


#investigate relationships for random effects
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Season.Ref) + geom_point()+ facet_wrap(~Analysis.Area)
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Season.Ref, color=Analysis.Area) + geom_boxplot() + theme_cowplot() # i would like to do a geom smooth plot of this too
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Season.Ref, color=Analysis.Area) + geom_violin() + theme_cowplot()
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Season.Ref, color=ADFG.Number) + geom_boxplot() + theme_cowplot() + theme(legend.position= "none")

##your experience depends on what group you are inb

#what is an average fishing vessel that is in all locations
ggplot(D7) + aes(y= log(CPUE_nom+0.001), x=Analysis.Area, color=ADFG.Number) + geom_boxplot() + theme_cowplot() #+ theme(legend.position= "none")


```




So, I wanted a model without smoothed effects. I probs should not use the gam function, but nlme or lme4 or something
Test if ranefs are necessary, please
It should be a glmm I think its a glmm. 4/29/24
- shoule ADFG.number be random or fixed effect????
- year should be fixed effect
- area should be random effect
- do year and area have interaction effects? Do year and vessel have interaction effects? do vessel and year have interaction effects?
--what is the best ranef structure??
- correlation matrix include??
- test vessel count (aa) as fixef too.
- maybe add week instead of jdate??
read the highlighted refs in the mauder and punt paper
```{r}
library(lme4)
library(lmerTest)


mod_g_new <- gam(log(CPUE_nom+0.001) ~ Season.Ref + s(vessel_count_aa, k=4) + s(Analysis.Area, bs="re") + s(ADFG.Number, bs="re"), method = "ML", data=D7)
summary(mod_g_new)
#the smoothed model, for funzies

mod_g_2 <- gam(log(CPUE_nom+0.001) ~ Season.Ref + s(Analysis.Area, bs="re") + s(ADFG.Number, bs="re"), method = "ML", data=D7)

AIC(mod_g_new, mod_g_2) #the more complex one wins(with vessel cound as a smoother). I do not undersand tho, why we would want to make vessel count smooth


#does vessel count matter? I do not think so.
#do area and year have interaction effects
#test just with lm for above
#do area and vessel have interaction effects

#global model - writing these, need sun
#m_interactions
#m_glob <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + (1|ADFG.Number) + (1+ Season.Ref|Analysis.Area), data=D7, REML=F) #not run, takes forevet
#m_glob_0.1 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + (1 + Season.Ref|ADFG.Number) + (1+ Season.Ref|Analysis.Area), data=D7, REML=F) #not run, takes forever
#takes forever

m_glob2 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + ADFG.Number + (1|Analysis.Area), data=D7, REML=F)
m_glob3 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + (1|ADFG.Number) + (1|Analysis.Area), data=D7, REML=F)
m_glob4 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + ADFG.Number + Analysis.Area, data=D7)
m_glob5 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + ADFG.Number + Analysis.Area + vessel_count_aa, data=D7)
#m_glob5.2 <- lm(log(CPUE_nom+0.001) ~ Season.Ref * ADFG.Number * Analysis.Area * vessel_count_aa, data=D7) #takes forever
m_glob6 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + (1|ADFG.Number) + (1|Analysis.Area), data=D7, REML=F) #gonna want to graph correlations
m_glob6_I <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + Season.Ref:vessel_count_aa + (1|ADFG.Number) + (1|Analysis.Area), data=D7, REML=F)
m_glob7 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + ADFG.Number + (1|Analysis.Area), data=D7, REML=F)
#m_glob7_I <- lmer(log(CPUE_nom+0.001) ~ Season.Ref * vessel_count_aa * ADFG.Number + (1|Analysis.Area), data=D7, REML=F) #takes forever
m_glob8 <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + (1|ADFG.Number) + Analysis.Area, data=D7, REML=F)

AIC(m_glob2, m_glob3, m_glob4,m_glob5,  m_glob6, m_glob6_I, m_glob7, m_glob8) #says glob 5. Let's chgeck for correlation tho. 6 is better than 3, if we choose ranef
summary(m_glob2)
summary(m_glob4)
summary(m_glob5) #the AIC prefers the linear model
summary(m_glob6) #but conceptually, I think we should go with this model
summary(m_glob6_I)
#vcov(m_glob6_I)

#based on theory, this is what I think the model should be:
##m_glob6, m_glob6_I, or m_glob7. 
AIC(m_glob6, m_glob6_I, m_glob7) #m_glob7_I appears to take forever
BIC(m_glob6, m_glob6_I, m_glob7, m_glob5) #syas 7 and 5 are close to each other
library(MuMIn)
AICc(m_glob6)
AICc(m_glob6_I)
AICc(m_glob7)
AICc(m_glob5) #need to account for those interaction effects tho


#REML the chosen model before mocing on
##m_glob6_I makes sense to me theoretically, even tho it does not win by model selection numbers. I should consider making ADFG number a fixed effect tho

m_glob6_IR <- lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + Season.Ref:vessel_count_aa + (1|ADFG.Number) + (1|Analysis.Area), data=D7, REML=T) #season ref could be year. Would it make a difference?



```

Model diagnostics

```{r}
#wil tyler's funciton work for me?
f_diagnostics <- function(x) {
  
  # qq plot
  ggplot()+
    stat_qq_line(aes(sample = resid(x, type = "deviance")), color = 2)+
    stat_qq(aes(sample = resid(x, type = "deviance")))+
    labs(x = "Theorical Quantiles", y = "Deviance Residuals", title = "Q-Q plot") -> p1
  
  # historgam
  ggplot()+
    geom_histogram(aes(x =  resid(x, type = "deviance")))+
    labs(x = "Residuals", y = "Count", title = "Histogram of residuals") -> p2
  
  # resid
  ggplot()+
    geom_point(aes(x = x$linear.predictors, y = resid(x, type = "deviance")))+
    geom_hline(yintercept = 0, linetype = 2)+
    labs(x = "Linear Predictor", y = "Residuals", title = "Resids. vs linear pred.") -> p3
  
  # resid vs fitted 
  ggplot()+
    geom_point(aes(x = x$fitted.values, y = x$model$cpue))+
    labs(x = "Fitted Values", y = "Response Values", title = "Response vs. Fitted") -> p4
  
  
  (p1 + p2) / (p3 + p4)
  
}
#end tyler's function

f_diagnostics(m_glob6)
```

Alex diagnostics
```{r}

plot(m_glob6_IR)
plot(m_glob6)
lmerTest::step(m_glob6)
lmerTest::step(m_glob6_I)
lmerTest::step(m_glob6_IR)

#step(m_glob6)

summary(m_glob6_IR)
ranef(m_glob6_IR)



```

Standardized (predicted)  CPUE
(from internet: Note I predict the log version as exp(predict(m) + sigma^2/2) because $E exp(X) = exp(mu + sigma^2)$ where $X \sim N(0, sigma^2)$. (This changes little here though.))
See: https://stats.stackexchange.com/questions/115571/back-transforming-regression-results-when-modeling-logy
```{r}
?predict.merMod
pred<- predict(m_glob6_IR, type = "response", se = TRUE) #newdata needs something?? right?

#newdata
newdata <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                               vessel_count_aa = round(mean(D7$vessel_count_aa),0),   #  unique(corr_spot_limited$jdate)... might need to expand and average this over all dates too
                               ADFG.Number = unique(D7$ADFG.Number), #table(corr_spot$ADFG.Number) #52131 #56332 #41228
                              Analysis.Area = unique(D7$Analysis.Area)
                               
 )

pred1 <- predict(m_glob6_IR, newdata, type = "response", se = TRUE)

pred_df <- data.frame(newdata, pred1$fit, pred1$se.fit)

#is this misleading? I have all vessels fising in all locations for this pred.
unique(D7 %>% filter(Analysis.Area=="Bradfield Canal") %>% select(ADFG.Number)) #30
unique(D7 %>% filter(Analysis.Area=="Lower Ernest Sound") %>% select(ADFG.Number)) #39
unique(D7 %>% filter(Analysis.Area=="Upper Ernest Sound") %>% select(ADFG.Number)) #51
unique(D7 %>% filter(Analysis.Area=="Zimovia Strait") %>% select(ADFG.Number)) #30
unique(D7$ADFG.Number) #88
###so, this might not be the best predict. Maybe I should leave the vessel part out, or choose a vessel in the middle?
###also, filter out unknown vessel at some point please

#what is, like, a very average fishing vessel, that is in all locations?
#or I could use jsut the fishing vessels that overlap? WHAT DID PHIL AND TYLER DO?!?!?!?!
###oh. see Spot_shrimp_ernest_clean_4.R code for an option.starts at 894. I weigh the ADFG.Number based on how many timest it appears in the dataset. How does that work for multiple areas tho??


#newdata
newdata2 <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                               vessel_count_aa = round(mean(D7$vessel_count_aa),0),   #  unique(corr_spot_limited$jdate)... might need to expand and average this over all dates too
                              # ADFG.Number = unique(D7$ADFG.Number), #table(corr_spot$ADFG.Number) #52131 #56332 #41228
                              Analysis.Area = unique(D7$Analysis.Area)
                               
 )

pred2 <- predict(m_glob6_IR, newdata2, type = "response", se = TRUE) #ok so adfg numver should be something


#also, remember that exp() will give you the mean, so use the adjustment to get the median plz!!!!
```




Analysis and model testing: individual analysis areas
```{r}
#Bradfield canal

#Lower ernest sound

#upper ernest sound

#Zimovia strait


```

Comparison graphs
```{r}

```

Results graphs
```{r}

```

Aside:
IS ADFG vessel accounted for?
-in email max says:

This is where shrimp survey data is located.
https://www.adfg.alaska.gov/analytics/saw.dll?Answers&path=%2Fshared%2FCommercial%20Fisheries%2FRegion%20I%2FInvertebrates%2FSurvey%2FShrimp%2FSpecimens%20with%20Pot%20Data

Survey catches are also reported in fish ticket data, recorded as Fishery: Test Fish, and Permit Holder: ADFG Sitka. These survey catches should be removed from calculations in CPUE and total reportable harvest.- I DO NOT SEE THESE REPORTED THO


_______

Take away from KAtie meeting:
focus on shrimp ticket for now.
Ask Max at what level does he make decisions. When he closes an area, what is that based off of?

