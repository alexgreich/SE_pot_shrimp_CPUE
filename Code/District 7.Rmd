---
title: "District 7"
author: "Alex Reich"
date: "2024-04-24"
output: html_document
---
Aside:
Argh, I had to upgrade to R 4.4.0 to get lme4 (the matrix package, specifically) to work. But now the r markdown settings are different and I can't default to the home directory being the project. So I will set that here:
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/agreich/OneDrive - State of Alaska/Desktop/Shrimp/Shrimp tickets (pot shrimp)/SE_pot_shrimp_CPUE')
```



Anyway, let's get started. This document will look at management unit District 7 for pot (spot) shrimp standardization. It will load in the (pre-wrangled) data, wrangle further for district 1, and then some EDA (focusing on variables of interest and correlation). The analysis will be by district with an HGAM (hierarchical GAM) with the variables of interest as fixed effects and Analysis Area as a random effect. I will do model selection on a few versions of this HGAM. I will then make graphs of the standardized CPUE (by district and) and whatever else Max wants. THEN, I will run individual models by analysis areas, ideally with an automated function, and compare the graphs of those automated functions to the cpue of the ranef model.This will help me decide if models should be by MANAGEMENT UNIT (larger) or by ANALYSIS AREA (smaller). In hindsight, I should start with District 7, since I have explored the Upper Ernest sound data extensively.Ok, now the RMD is named accordingly 


Load libraries
```{r}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(viridis)
library(RColorBrewer)
library(mgcv)
```


Load the data and select for D7
```{r}
wrangled_shrimp <- read.csv("Data/wrangled shrimp focus years.csv")
D7 <- wrangled_shrimp %>% filter(Management_unit == "District 7") %>%
  mutate(Analysis.Area = factor(Analysis.Area),
         ADFG.Number = factor(ADFG.Number),
         Season.Ref = factor(Season.Ref)
         )#make things factors for the gams

unique(D7$Analysis.Area)

```


District 7 contains analysis areas:
  Bradfield Canal
  Lower Ernest Sound
  Upper Ernest Sound
  Zimovia Strait
  
  
  
## Exploratory Data Analysis for D7
Variables of interest:
Random effect: Analysis.Area
Fixed effects: jdate (smoothed and... cyclical?), vessel # (the count of vessels), ADFG # (individual vessel (fixed or random effect??)), Season aka year, 
--If I do not include jdate, simplifies things?
Response: nominal cpue

Q: should I do something besides a log-transformation?
THIN OUT
```{r}

#cpue dist
ggplot(D7) + aes(x=CPUE_nom) + geom_density()
ggplot(D7) + aes(x=log(CPUE_nom+0.001)) + geom_density()
qqnorm(log(D7$CPUE_nom)) #that kind of looks bad. Maybe somehting other than log-trans?
qqnorm(D7$CPUE_nom)

ggplot(D7) + aes(x=CPUE_nom) + geom_density()+facet_wrap(~Analysis.Area)
ggplot(D7) + aes(x=log(CPUE_nom+0.001)) + geom_density()+facet_wrap(~Analysis.Area)

#cpue by year
ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_point() #ther is a big outlier
ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_boxplot(outliers = F)

ggplot(D7) + aes(x=factor(Season.Ref), y=CPUE_nom) + geom_boxplot(outliers = F) + facet_wrap(~Analysis.Area) #cpue varies... cyclically with time. Is season a fixed effect? I want to estimate it, so probs not. its def not linear.

#catch by year
ggplot(D7) + aes(x=factor(Season.Ref), y=total_weight) + geom_boxplot() #this is total weight per fish ticket.
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot()
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot(outliers=F)

ggplot(D7) + aes(x=factor(Season.Ref), y=total_weight) + geom_boxplot() + facet_wrap(~Analysis.Area) #max pots per fish ticket
ggplot(D7) + aes(x=factor(Season.Ref), y=max_pots_2) + geom_boxplot(outliers=F) + facet_wrap(~Analysis.Area)


#cpue and vessel count
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot()
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot(outliers=F)
ggplot(D7) + aes(x=factor(vessel_count_mgmt_u), y=log(CPUE_nom)) + geom_boxplot(outliers=F) + facet_wrap(~Analysis.Area)

#cpue and district


#cpue and jdate



#correlation plot
library(corrplot)
D7_interest_cor <- D7 %>% select(CPUE_nom, jdate, vessel_count_mgmt_u)
cor_prep <- cor(D7_interest_cor)
corrplot(cor_prep)
?pairs


#check model residuals, see if we need ar1 correlation in the model
```





Model selection 5/15/24
```{r}

#ok can breifly test ranefs
M_ranef <-  lmer(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + Season.Ref:Analysis.Area + Analysis.Area + (1|ADFG.Number), data=D7, REML=T)


M_noranef <-  lm(log(CPUE_nom+0.001) ~ Season.Ref +vessel_count_aa + ADFG.Number + Season.Ref:Analysis.Area + Analysis.Area, data=D7)
AIC(M_ranef, M_noranef) #no ranefs

summary(M_ranef)



#global with ranef and interactions

M2 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + vessel_count_aa + ADFG.Number +Analysis.Area + Season.Ref:Analysis.Area, data=D7)

M3 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + ADFG.Number + Analysis.Area + Season.Ref:Analysis.Area, data=D7)

M4 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + ADFG.Number +Analysis.Area, data=D7)

M5 <- lm(log(CPUE_nom+0.001) ~ Season.Ref + Analysis.Area + Season.Ref:Analysis.Area, data=D7)

M_null <- lm(log(CPUE_nom+0.001) ~ Season.Ref+ Analysis.Area, data=D7)

AIC(M2, M3, M4, M5, M_null) #M3 wins
#says that vessel count does not matter...


summary(M3)

```

Impute values, and get values in log-space
Uncertainty: the method I chose for this.
```{r}
D7$logCPUE <- log(D7$CPUE_nom + 0.001)

#impute values so we dont have missing year:stat area problems
library(mice)

#expand dataset so that the NA's are where I want them...?
##is just one value between yera and analysis area enough?
##I'll take the mean of each analysis area, and get missing values too
temp1 <- D7 %>%
  group_by(Season.Ref, Analysis.Area) %>%
  summarise(logCPUE_mean = mean(logCPUE)) #mean of nominal or... logged cpue?

temp2 <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                       Analysis.Area = unique(D7$Analysis.Area)
                      )

temp3 <- full_join(temp2, temp1)
#View(temp3) #now I have my averages with my NA's

#alt method: I could do by vessel, impute as well; need to weight the only 1 value for the missing values somehow.

#use mice

md.pattern(temp3)

imp <- mice(data=temp3, method= "mean", m=1, maxit=1 )
imp2 <- complete(imp) #imputed data
 
#now put imputed data back in the dataframe, with the mode vessel?



#I could also impute the missing value with ALLL of the vessels, years, analysis areas in a district... might be extra though
temp5 <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                       Analysis.Area = unique(D7$Analysis.Area),
                      ADFG.Number = unique(D7$ADFG.Number)
                      )
D7_sub <- D7 %>% select(Season.Ref, Analysis.Area, ADFG.Number, logCPUE)

temp6 <- full_join(temp5, D7_sub)

md.pattern(temp6)


imp3 <- mice(data=temp6, method="mean", m=1, maxit=1) #maybe try diff method: "norm.nob"?
imp3.5 <- mice(data=temp6, m=1, maxit=1)

imp4 <-complete(imp3)
View(imp4) #ALL missing values are 1.04??
View(complete(imp3.5)) #IDK what method we used here but looks better than the mean method -> pmm, predictive mean matching


#oh wait, try imputing for just some columns but not others. I can do that I think
##in the method specification of mice()
##can add na for just the missing combination of year and analysis area, impue for that
```


Predict 5/15/24
```{r}
table(D7$ADFG.Number)


std_dat<- expand.grid(Season.Ref = unique(D7$Season.Ref), #do I need to extrapolate for areas/years taht do not exist??
                              Analysis.Area = unique(D7$Analysis.Area), #does not like east behm canal
                              #Hooks = round(mean(cpue_dat$Hooks),0), 
                              #Line_no = 2, #mean(cpue_dat$Line_no) unique(cpue_dat$Line_no)
                              ADFG.Number = factor(52131) #52131 appears 399 times.
                      )

pred_cpue <- predict(M3, std_dat, type = "response", se = TRUE) #does have the doubtful cases error, with both 71619  and 33175
#oh so it works for M13 but not for M12?


#OR, what if I just skipped the years:area combinations taht dont exist? Do I need to predict for those?!!!!!!!!!!!
##cant I just predict for the situations where CPUE DOES exist??

```


Standardized (predicted)  CPUE
(from internet: Note I predict the log version as exp(predict(m) + sigma^2/2) because $E exp(X) = exp(mu + sigma^2)$ where $X \sim N(0, sigma^2)$. (This changes little here though.))
See: https://stats.stackexchange.com/questions/115571/back-transforming-regression-results-when-modeling-logy
```{r}
?predict.merMod
pred<- predict(m_glob6_IR, type = "response", se = TRUE) #newdata needs something?? right?

#newdata
newdata <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                               vessel_count_aa = round(mean(D7$vessel_count_aa),0),   #  unique(corr_spot_limited$jdate)... might need to expand and average this over all dates too
                               ADFG.Number = unique(D7$ADFG.Number), #table(corr_spot$ADFG.Number) #52131 #56332 #41228
                              Analysis.Area = unique(D7$Analysis.Area)
                               
 )

pred1 <- predict(m_glob6_IR, newdata, type = "response", se = TRUE)

pred_df <- data.frame(newdata, pred1$fit, pred1$se.fit)

#is this misleading? I have all vessels fising in all locations for this pred.
unique(D7 %>% filter(Analysis.Area=="Bradfield Canal") %>% select(ADFG.Number)) #30
unique(D7 %>% filter(Analysis.Area=="Lower Ernest Sound") %>% select(ADFG.Number)) #39
unique(D7 %>% filter(Analysis.Area=="Upper Ernest Sound") %>% select(ADFG.Number)) #51
unique(D7 %>% filter(Analysis.Area=="Zimovia Strait") %>% select(ADFG.Number)) #30
unique(D7$ADFG.Number) #88
###so, this might not be the best predict. Maybe I should leave the vessel part out, or choose a vessel in the middle?
###also, filter out unknown vessel at some point please

#what is, like, a very average fishing vessel, that is in all locations?
#or I could use jsut the fishing vessels that overlap? WHAT DID PHIL AND TYLER DO?!?!?!?!
###oh. see Spot_shrimp_ernest_clean_4.R code for an option.starts at 894. I weigh the ADFG.Number based on how many timest it appears in the dataset. How does that work for multiple areas tho??


#newdata
newdata2 <- expand.grid(Season.Ref = unique(D7$Season.Ref),
                               vessel_count_aa = round(mean(D7$vessel_count_aa),0),   #  unique(corr_spot_limited$jdate)... might need to expand and average this over all dates too
                              # ADFG.Number = unique(D7$ADFG.Number), #table(corr_spot$ADFG.Number) #52131 #56332 #41228
                              Analysis.Area = unique(D7$Analysis.Area)
                               
 )

pred2 <- predict(m_glob6_IR, newdata2, type = "response", se = TRUE) #ok so adfg numver should be something


#also, remember that exp() will give you the mean, so use the adjustment to get the median plz!!!!
```




Analysis and model testing: individual analysis areas
```{r}
#Bradfield canal

#Lower ernest sound

#upper ernest sound

#Zimovia strait


```

Comparison graphs
```{r}

```

Results graphs
```{r}

```

Aside:
IS ADFG vessel accounted for?
-in email max says:

This is where shrimp survey data is located.
https://www.adfg.alaska.gov/analytics/saw.dll?Answers&path=%2Fshared%2FCommercial%20Fisheries%2FRegion%20I%2FInvertebrates%2FSurvey%2FShrimp%2FSpecimens%20with%20Pot%20Data

Survey catches are also reported in fish ticket data, recorded as Fishery: Test Fish, and Permit Holder: ADFG Sitka. These survey catches should be removed from calculations in CPUE and total reportable harvest.- I DO NOT SEE THESE REPORTED THO


_______

Take away from KAtie meeting:
focus on shrimp ticket for now.
Ask Max at what level does he make decisions. When he closes an area, what is that based off of?

